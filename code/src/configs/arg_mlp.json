{
    "model": "mlp",
    "optim": "adamw",
    "model_path": "../model/mlp.pth",
    "modulus": 97,
    "seed": 0,
    "epoch_num": 100000,
    "lr": 0.001,
    "batch_size": 256,
    "test_alpha": 0.4,
    "step_lr_step_size": 100,
    "step_lr_gamma": 0.98,
    "hidden_size": 256,
    "n_layers": 5
}